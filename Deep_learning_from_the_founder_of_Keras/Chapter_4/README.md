# 4장. 머신 러닝의 기본 요소
> 머신 러닝에 필요한 개념 정리하기
***

## 1. 머신 러닝의 네가지 분류
* ### 지도 학습 : 샘플 데이터가 주어지면 타깃에 입력 데이터를 매핑하여 학습
    > 광학 문자 판독, 음성 인식, 이미지 분류, 언어 번역 등

    > 지도 학습은 거의 __분류__ 와 __회귀__ 로 구성되지만 다음처럼 특이한 변종도 많다
    * 시퀀스 생성 : 사진이 주어지면 이를 설명하는 __캡션을 생성__ 한다. 
    * 구문 트리 에측 : 문장이 주어지면 __구문 트리를 예측__ 한다.
    * 물체 감지 : 사진이 주어지면 사진 안의 __특정 물체 주위에 경계 상자를 그린다.__ (분류 문제로 표현되거나, 경계 상자의 좌표를 벡터 회귀로 예측하는 회귀와 분류가 결합된 문제로 표현 가능하다)
    * 이미지 분할 : 사진이 주어지면 픽셀 단위로 특정 물체에 마스킹을 한다.
* ### 비지도 학습 : 어떤 타깃도 사용하지 않고 입력 데이터에 대한 변환을 찾는다.
    > 데이터 시각화, 압축, 노이즈 제거 또는 데이터의 상관관계를 더 잘 이해하기 위해 사용한다.

    * 비지도 학습은 종종 지도학습 전에 __데이터셋 이해를 위해__ 필수로 거치는 단계로 __차원 축소__ 와 __군집__ 이 비지도 학습에서 잘 알려진 범주이다.
* ### 자기 지도 학습 : 지도 학습이지만 사람이 만든 레이블을 사용하지 않는다.(사람이 개입하지 않는 지도학습)
    > 학습이 지도되어야 하기에 레이블일 필요하지만 보통 __경험적인 알고리즘을 사용__ 해서 입력 데이터로부터 생성한다.
    
    * 오토인코더 : 잘알려진 자기 지도 학습으로써, 생성된 타깃은 수정하지 않은 원본 입력이다. 
    > 같은 방식으로 지난 프레임에 대한 비디오의 다음 프레임 예상, 다음 단어 예상등이 자기 지도 학습의 예이다.
* ### 강화 학습 : 에이전트(모델)가 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하게 학습된다.
    * 강화 학습을 훈련된 신경망은 게임 화면을 입력, 게임 점수를 최대화 하기 위해 행동을 출력할 수 있다
    > 현재 강화학습은 연구 영역이 많지만 나중에는 세상의 많은 애플리케이션을 대체할 것으로 예상된다.
* ### 분류와 회귀에서 사용하는 용어
    * 샘플 & 입력 : 모델에 주입될 __하나의 데이터 포인트__
    * 예측 & 출력 : 모델로부터 __나오는 값__
    * 타깃 : __정답__ , 외부 데이터 소스에 근거하여 모델이 완벽하게 __예측해야 하는 값__
    * 예측 오차 & 손실 값 : 모델의 __예측과 타깃 사이의 거리를 측정__ 한 값
    * 클래스 : 분류 문제에서 선택할 수 있는 가능한 __레이블의 집합__ (고양이와 강아지를 분류할 때 클래스는 고양이와 강아지 두개)
    * 레이블 : 분류 문제에서 __클래스 할당의 구체적인 사례__ (#23에 강아지 클래스가 들어있으면 강아지는 사진 #23의 레이블)
    * 참 값 & 꼬리표 : 데이터셋에 대한 __모든 타깃__ 
    * 이진 분류 : 각 입력 샘플이 2개의 배타적인 범주로 구분되는 __분류 작업__
    * 다중 분류 : 각 입력 샘플이 __2개 이상의 범주__ 로 구분되는 분류 작업
    * 다중 레이블 분류 : 각 입력 샘플이 __여러 레이블에 할당될 수 있는__ 분류 작업(보통 이미지마다 레이블의 개수가 다름)
    * 스칼라 회귀 : 타깃이 __연속적인 스칼라__ 값인 작업.(주택 가격 예측 - 각기 다른 타깃 가격이 연속적인 공간 형성)
    * 벡터 회귀 : __타깃이 연속적인 값의 집합__ 인 작업.(여러 개의 값에 대한 회귀)
    * 미니 배치 & 배치 : 모델에 의해 __동시에 처리되는__ 소량의 샘플 묶음(2의 거듭제곱으로). 훈련 시 미니배치마다 한번씩 모델의 가중치에 적용해야 할 경사 하강법 업데이트 값을 계산한다.
***
## 2. 머신 러닝 모델 평가
* ### 데이터 분할
    > 모델 평가의 핵심은 데이터를 __훈련, 검증(평가), 테스트(모델 출시시 한번만 테스트)__ 로 나누는 것이다.
    * #### 데이터를 훈련 & 테스트 데이터로만 나누지 않는 이유?
    > 모델 개발시 모델 __하이퍼 파라미터(층의 수, 유닛 수)__ 등의 설정을 튜닝하기 때문. 즉, 테스트 데이터로 모델 훈련 후, 검증 세트로 학습을 검사하는 데 검증 세트도 사용할 수록 __과적합__ 되기에 완전히 새로운 데이터(테스트 데이터)로 검사한다.
    * #### 즉, 모델은 간접적으로라도 테스트 세트에 대한 정보를 얻어서는 안된다.
    * 데이터를 훈련, 검증, 테스트로 나눌 때 도움되는 검증 방법이 있다.
        * 단순 홀드아웃 검증
        * K-겹 교차 검증
        * 셔플링을 사용한 반복 K-겹 교차 검증
* ### 단순 홀드 아웃 검증 
    > 데이터의 일정량을 테스트 세트로 떼어 놓고 남은 데이터중 훈련과 검증 세트를 만든다.
    __단, 평가 방법이 너무 단순하다__
    > 데이터가 적을 시 검증과 테스트의 샘플이 적어 전체 데이터를 대표하지 못하고 난수로 데이터를 셔플링 할 시 모델 성능이 달라진다.
    ```
    np.random.shuffle(data)  # 데이터 섞기(일반적으로는 섞는다)
    validation_data = data[:10000] # 검증 세트를 만듦(0부터 9999까지)
    data = data[10000:] # 훈련 데이터(10000부터 끝까지)
    training_data = data[:] # 훈련 세트를 만듦

    model = get_model()  # 모델 생성
    model.train(training_data) # 모델 훈련
    score = model.evalute(validation_data) # 모델 평가
    
    # 여기서 모델 튜닝, 훈련, 평가, 튜닝 ....

    model.get_model()
    model.train(np.concatenate([training_data, validation_data])) # 하이퍼파라미터 튜닝 끝날 시 데스트 데이터를 제외한 모든 데이터로 모델을 훈련시킨다
    test_score = model.evaluate(test_data)
    ```
* ### K-겹 교차 검증
    > 데이터를 K개의 동일한 크기의 분할로 나누고 각 분할에 대해 __K-1개로 모델 훈련, 남은 1개로 검증을 한다.(검증 데이터가 겹치지 않고 K번동안)__ 최종 점수는 검증 점수의 평균.

    ```
    k = 4
    samples = len(data) // k

    np.random.shuffle(data)
    score = []
    for fold in range(k) :
        validation_data = data[samples * fold : samples * (fold + 1)]  # 검증 데이터 부분 결정
        training_data = data[:samples * fold] + data[samples *(fold+1):] # 남은 데이터를 훈련 데이터로 사용. \

        model = get_model()  # 새 모델 생성
        model.train(training_data)
        score = model.evaluate(validation_data)
        scores.append(score)
    score = np.average(scores) # 검증 점수 : K개 폴드의 검증 점수 평균

    model = get_model()
    model.train(data)
    test_score = model.evaluate(test_data) # 테스트 데이터를 제외한 전체 데이터로 최종 모델 학습
    ``` 
* ### 셔플링을 사용한 반복 K-겹 교차 검증
    > 데이터가 적고 정확한 평가를 할때 사용, K-겹 교차 검증 전 매번 데이터를 무작위로 섞은뒤 반복하는 것이다
    * 최종 점수는 K-겹 교차 검증을 실행해 얻은 점수의 평균
* ###  평가 방식 선택시 유념할 점
    * __대표성 있는 데이터__ : 훈련 & 테스트 세트에 대한 대표성이 있어야 하기에 나누기 전에 __데이터를 무작위로 섞는다__
    * __시간의 방향__ : 과거로부터 미래를 예측시, 데이터를 __무작위로 섞어서는 안된다(미래 정보 누설)__ 이럴 때는 테스트 세트 데이터가 미래 것이어야 한다.
    * __데이터 중복__ : 데이터 중복을 조심한다
***
## 2. 데이터 전처리, 특성 공학, 특성 학습
> 데이터 전처리 목적은 원본 데이터를 신경망에 적용하기 쉽게 하기 위해서이며 __벡터화, 정규화, 누락 값 다루기, 특성 추출__ 등이 있다
* ### 벡터화
    > 신경망에서 모든 입력 & 타깃은 __부동 소수 데이터인 텐서여야한다.__ 
    * 처리해야 할 게 무엇이든 먼저 텐서로 변환해야 하며 이 단계를 __데이터 벡터화__ 라고 한다.
* ### 값 정규화
    > 보통 비교적 __큰 값이나 균일하지 않은 데이터__ 를 신경망에 주입하는 것은 위험하다. 이러면 업데이트 그래디언트가 커져 네트워크 수렴을 방해하기에 네트워크 학습을 위해 데이터는 다음 특징을 따라야 한다.
    * 작은 값을 취한다. 보통 __값이 0~1사이이다.__
    * 균일해야 하기에 __모든 특성이 대체로 비슷한 범위__ 를 가져야 한다.
    > 각 특성별로 __평균이 0이 되고 각 틍성별 표준 편차가 1이 되도록 정규화__ 하는 것은 자주 사용하고 도움이 된다.
    ```
    x -= x.mean(axis=0)
    x /= x.std(axis=0)
    ```
* ### 누락 값 다루기
    > 누락값은 __0이라고 넣는다__ 또는 특성을 전부 제외시킬 수도 있다.
* ### 특성 공학
    > 특성공학은 데이터 & 머신러닝 알고리즘에 관한 지식을 사용하는 단계로 데이터 주입 전 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되게 한다.
    __즉, 특성을 더 간단한 방식으로 표현해 문제를 쉽게 만든다.__
    > 심층 신경망 사용시 특성 공학이 중요한 이유
    * 좋은 특성은 적은 자원을 사용해 문제럴 더 멋지게 풀어낼 수 있다
    * 좋은 특성은 더 적은 데이터로 문제를 풀 수 있다.
***
## 과대적합과 과소적합
* __최적화__ : 훈련 데이터에서 최고의 성능을 얻으려 모델을 조정하는 과정
* __일반화__ : 훈련된 모델이 새 데이터에서 잘 수행되는 것
* __과소적합__ : 훈련 데이터 손실이 낮을 때 테스트 데이터 손실도 낮아짐.
* __규제__ : 과대적합을 피하는 처리 과정
* ### 네트워크 크기 축소
    > 과대적합을 막는 단순한 방법은 학습 파라미터(층의 수, 층의 유닛 수) 수를 줄이는 것.
    __즉, 손실을 최소화하기 위해 타깃에 대한 예측 성능을 가진 압축 표현 학습 및 충분한 파라미터를 가진 모델을 사용해야 한다__
* ### 가중치 규제 추가
    > __가중치 규제__ : 과대 적합 완화를 위한 일반적인 방법으로 __네트워크 복잡도에 제한을 둬 가중치가 작은 값을 가지도록 강제__ 하는것으로, 손실 함수에 큰 가중치에 연관된 비용 추가
    * __L1 규제__ : 가중치 절댓값에 비례하는 비용 추가 
    * __L2 규제(가중치 감쇠)__ : 가중치 제곱에 비례하는 비용 추가
    ```
    모델.add(layers.Dense(유닛 수, kernel_regularizer=regularizers.l2(0.001)))
    # l2(0.001) : 가중치 행렬 모든 원소를 제곱 후 0.001을 곱해 네트워크 전체 손실에 더해짐

    # l1 규제
    모델.add(layers.Dense(유닛 수, kernel_regularizer=regularizers.l1(0.001)))
    
    # l1, l2 규제
    모델.add(layers.Dense(유닛 수, kernel_regularizer=regularizers.l1_l2(l1 = 0.001, l2 = 0.001)))
    ```
* ### 드롭아웃 추가
    > 과대 적합 방지를 위해 훈련하는 동안 무작위로 층의 일부 출력 특성 제외
    ```
    model.add(layers.Dropout(0.5)) # 절반을 0으로
    ```
* ### 신경망에서 과대 적합 방지를 위한 방법
    * 많은 훈련 데이터 사용
    * 네트워크의 용량 감소
    * 가중치 규제 추가
    * 드롭아웃을 추가
***
## 머신러닝 작업 흐름
* ### 주어진 문제와 훈련 데이터를 정의한다. 이 데이터를 수집하고 필요하면 레이블을 태깅한다
* ### 성공 측정 방법을 선택한다. 검증 데이터에서 모니터링할 지표를 선택한다.
* ### 평가 방법을 결정한다. 
    > 모델에 따른 활성화 함수 & 손실 함수
    * 이진 분류 : 시그모이드 & binary_crossentropy
    * 단일 렝블 다중 분류 : 소프트맥스 & categorical_crossentropy
    * 다중 레이블 다중 분류 : 시그모이드 & binary_crossentropy
    * 임의 값에 대한 회귀 : 없음 & mse
    * 0과 1사이의 회귀 : 시그모이드 & mse or binary_crossentropy
* ### 단순 랜덤 선택 모델보다 나은 통계적 검정력이 있는 첫번째 모델을 만든다.
* ### 검증 데이터의 성능에 기초해 모델을 규제하고 하이퍼 파라미터 튜닝한다. 머신러닝 연구 대부분은 이단계이다.