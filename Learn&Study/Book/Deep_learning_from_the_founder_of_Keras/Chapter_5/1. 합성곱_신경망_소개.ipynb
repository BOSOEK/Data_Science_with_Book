{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 합성곱 신경망(CNN) 소개\n",
    "   > 컨브넷 정의와 컨브넷이 컴퓨터 비전 관련 작업에 맞는 이유에 대해 이론적 배여을 알아보기 전, 컨브넷 예제로 MNIST 숫자 이미지 분류에 컨브넷을 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 컨브넷이 (image_height, image_width, image_channels) 크기를 사용하는게 중요하다. \n",
    "\n",
    "* #### 컨브넷 구조 출력하기\n",
    "> __model.summary()__ : 신경망 구조 출력(시작 부분이 신경망 입구, 마지막 부분이 신경막 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 추가\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1789 - accuracy: 0.9454\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 0.0474 - accuracy: 0.9853\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 0.0329 - accuracy: 0.98990s - l\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 0.0249 - accuracy: 0.99210s - loss: 0.0248 - accuracy: 0.\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 0.0211 - accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207165bb670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST 이미지에 컨브넷 훈련하기\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "0.9929999709129333\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc) # 정확도 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 연산\n",
    "   > 완전 연결 층과 합성곱 층 차이는 Dense 층은 입력 특성 공간에 있는 전역 패턴을 학습하지만 __합성곱 층은 지역 패턴__ 을 학습한다 \n",
    "   \n",
    "   > 완전 연결 계층(일반적 신경망)은 __데이터의 형상을 무시하고 1차원 데이터로 변화__ 하는데 반해 합성곱 계층은 __형상을 유지하여 형상에 담긴 정보를 살릴 수 있다.(이미지 분류처럼 위치 정보가 중요할 때 사용)__\n",
    "    \n",
    "   > 컨브넷의 두가지 성질\n",
    "   * __학습된 패턴은 평행 이동 불변성을 가진다.__ 즉, 한쪽에서 찾은 패턴을 다른 쪽에서도 찾는다.\n",
    "   * __패턴의 공간적 계층 구조 학습__ : 층을 더해 갈수록 복잡한 패턴 학습\n",
    "    \n",
    "   > 합성곱의 핵심적인 파라미터 2개\n",
    "   * __입력으로부터 뽑아낼 패치의 크기__ : 3 X 3 또는 5 X 5크기를 사용한다.\n",
    "   * __특성 맵의 출력 깊이__ : 합성곱으로 계산할 필터 수.\n",
    "    \n",
    "   > 합성곱 작동 방식\n",
    "   * 입력 데이터에서 필터의 크기(가로, 세로)에 맞게 __윈도우가 슬라이딩하며 필터를 적용__ 한다.\n",
    "   * 입력 데이터의 크기만큼 필터 적용한 __데이터를 1D 벡터로 변환__ 한다.\n",
    "   * 초기의 데이터의 위치에 __데이터를 합친다.(결과는 3D)__\n",
    "    \n",
    "   __즉, 합성곱은 입력이 3D이면서 출력도 3D이다__\n",
    "    \n",
    "   * ### 경계 문제와 패딩 이해하기\n",
    "        > 합성곱은 연산시마다 출력 결과가 점점 작아진단. 즉, 언젠가는 너무 작아져서 출력이 1이된다. 이때, __입력과 동일한 높이, 너비를 가진 출력 맵을 얻고 싶을때 패딩(0)을 사용한다__\n",
    "        \n",
    "        > Conv2D에서 패딩은 padding 매개변수로 설정하며 ```valid```는 패딩 미사용, ```same```은 입력과 동일한 출력(패딩)이라는 뜻이다.\n",
    "    \n",
    "   * ### 합성곱 스트라이드 이해하기\n",
    "        > 스트라이드는 __윈도우 중앙 타일이 지나가는 타일 개수__ 이다. 기본은 1이며 그 이상의 수를 사용할 수도 있지만 스트라이크를 증가하면 출력 맵의 크기가 줄어든다.\n",
    "   * ### 최대 풀링 연산\n",
    "       > 입력 특성 맵에서 합성곱처럼 3X3에 스트라이드 1이 아닌 __2X2에 스트라이드 2__ 를 사용하며 __채널 별 최대값을 출력__ 하고, 강제적으로 __특성 맵을 다운샘플링__ 한다\n",
    "       \n",
    "       > 특성 맵을 다운샘플링 하는 이유, __합성곱으로만 모델을 만들었을때의 문제점__\n",
    "       * 특성의 공간적 계층 구조 학습에 도움되지 않으며 학습할수록 __초기 입력에 관한 정보가 적어져서__ 학습에 맞지 않다\n",
    "       * 맵이 클시에 원소가 많아져서 __가중치가 많아지고 과대적합이 발생__ 한다.\n",
    "       \n",
    "       > 최대값을 취하는 대신 패치의 __채널별 평균을 계산하는 평균 풀링__ 도 있지만 최대 풀링이 더 작동이 잘된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
