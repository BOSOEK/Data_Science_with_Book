{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/BOSOEK/Machine_Learning/blob/main/Learn%26Study/Book/Deep_learning_from_the_founder_of_Keras/Chapter_5/3_%EC%82%AC%EC%A0%84_%ED%9B%88%EB%A0%A8%EB%90%9C_%EC%BB%A8%EB%B8%8C%EB%84%B7_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avua-OrOu6iB"
   },
   "source": [
    "# 사전 훈련된 컨브넷 사용하기\n",
    "> 작은 이미지 데이터셋에 딥러닝을 적용하는 일반적 & 효과적인 방법은 __사전 훈련된 네트워크(문제를 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크)__ 를 이용하는 것이다.\n",
    "\n",
    "> 이 코드에서는 ImageNet 데이터셋에서 훈련된 대규모 컨브넷을 사용함\n",
    "* __VGG16__ : 간단하며 ImageNet 데이터셋에 널리 사용되는 컨브넷 구조이다.\n",
    "> VGG16모델은 케라스 패키지로 포함되어 있으며, ```keras.applications``` 모듈에서 임포트 가능하다.   \n",
    "> ```keras.applications``` 모듈에서 사용 가능한 이미지 분류 모델리스트\n",
    "    * Xception\n",
    "    * Inception V3\n",
    "    * ResNet50\n",
    "    * VGG16\n",
    "    * VGG19\n",
    "    * MobileNet\n",
    "\n",
    "* 사전 훈련된 네트워크를 시작하는 방법은 __특성 추출__ 과 __미세 조정__ 이 있다.\n",
    "\n",
    "### 1. 특성 추출\n",
    "> 네트워크 표현으로 새로운 샘플에서 흥미로운 특성을 뽑아 내는 것.\n",
    "\n",
    "> 컨브넷은 이미지 분류를 위해 두 부분으로 구성된다.  \n",
    "    1. 합성곱 기반 층 : 합성곱과 풀링 층  \n",
    "    2. 완전 연결 분류기 : 한 층의 모든 뉴런이 다음 층의 모든 뉴런과 연결\n",
    "* __컨브넷(CNN)의 특성 추출은 사전 훈련된 네트워크의 합성곱 기반 층을 선택해 새로운 데이터 통과후, 그 출력으로 새로운 분류기를 훈련한다.__\n",
    "> 합성곱 층만 재사용 하는 이유 : 분류기는 사진에 어떤 __클래스가 존재할 확률 정보__ 만 담고 있으며, 완전 연결 층은 공간 개념을 제거하지만 __합성곱은 객체 위치를 고려__ 한다.  \n",
    "> 즉, __객체 위치가 중오한 이미지 문제__ 에서는 분류기에서 만든 특성은 쓸모가 없다.\n",
    "\n",
    "* VGG16 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QiO25u7Av1Go"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VGG16' from 'keras.applications' (C:\\Users\\김보석\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\applications\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-078f5bf8ef6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# VGG16 합성곱 기반 층 만들기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m conv_base = VGG16(weights='imagenet',\n\u001b[0;32m      5\u001b[0m                  \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'VGG16' from 'keras.applications' (C:\\Users\\김보석\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\applications\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# VGG16 합성곱 기반 층 만들기\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__VGG16 매개변수__\n",
    "* weights : 모델을 초기화할 가중치 체크포인트를 지정함.\n",
    "* include_top : 네트워크 최상위 완전 연결 분류기를 포함할지 안할지 지정.(기본은 데이터의 클래스에 대응되는 완전 연결 분류기를 포함함)\n",
    "* input_shape : 네트워크에 주입할 이미지 텐서의 크기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__최종 특성 맵 크기(4, 4, 512) 위에 완전 연결 층 놓기 위한 두가지 방법__\n",
    "* 새로운 데이터셋의 합성곱 기반 층의 출력을 __독립된 완전 연결 분류기의 입력으로 사용한다.(데이터 증식 X)__\n",
    "* 모델위에 __Dense 층을 쌓아 확장한 후 입력 데이터에서 엔드-투-엔드__ 로 전체 모델을 실행한다.(데이터 증식 O)\n",
    "\n",
    "#### 데이터 증식을 사용하지 않는 빠른 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 합성곱 기반 층을 사용한 특성 추출하기\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count) :\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode = 'binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator :\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count :\n",
    "            break  # 제너레이터는 루프 안에서 무한하게 만들어 내기에 모든 이미지를 한번씩 처리하고 나면 중지\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출된 특성을 (samples, 4, 4, 512)에서 (samples, 8192)로 펼치기\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 연결 분류기를 정의하고 훈련하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 손실 & 정확도 곡선 그리기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 증식을 사용한 특성 추출\n",
    "> conv_base 모델을 확장하고 입력 데이터를 사용하여 엔드-투-엔드로 실행\n",
    "\n",
    "__연산이 크기 때문에 GPU 환경에서 실행해야 한다__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 기반 층 위에 완전 연결 분류기 추가하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> VGG16의 합성곱 기반층 위에 추가한 분류기는 2백만개의 파라미터를 가진다.\n",
    "\n",
    "* 모델 컴파일 & 훈련 전에 합성곱 기반층을 동결하는 것은 중요하다. \n",
    "> 층을 동결하는 것은 가중치 업데이트를 막는다는 뜻이다.\n",
    "\n",
    "> 층을 동결하지 않으면 합성곱 기반층에 의해 __사전에 학습된 표현이 훈련동안 수정되어__ 사전 학습 표현을 훼손한다.\n",
    "* trainable 속성 False로 네트워크를 동결할 수 있다.\n",
    "> trainable 속성 변경후 모델을 다시 컴파일 해야 변경 사항이 적용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('conv_base를 동결하기 전 훈련되는 가중치 수 : ', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "\n",
    "print('conv_base를 동결 후 훈련되는 가중치 수 : ', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# 검증데이터는 증식되어서는 안된다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=20,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1,\n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.1,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # 검증 데이터 증식 X\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,     # 타깃 폴더\n",
    "        target_size(150, 150),   # 이미지 크기 설정\n",
    "        batch_size = 20,\n",
    "        class_mode = 'binary')  # binary_cros손실이라 이진 레이블로 \n",
    "        \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(150, 150),\n",
    "            batch_size = 20,\n",
    "            class_mode = 'binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=30,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps=50,\n",
    "        verbose=2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfJnD86tJP7bA+Bhh2jikJ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "3. 사전_훈련된_컨브넷_사용하기.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
