{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNr/LI6J/65gfYt5uprhgvm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BOSOEK/Machine_Learning_with_Book/blob/main/Deep_Learning_Chatbot_for_First_Time/Models/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujKWZY5qPiNn"
      },
      "source": [
        "# 개채명 인식(Named Entitiy Recognition) - NER\n",
        "> __문장 내의 단어가 인물, 장소, 날짜 등을 의미__하는지 인식하는 것으로 이런 프로그램을 __개채명 인식기__ 라고 한다\n",
        "\n",
        "### BIO 표기법\n",
        "> 각 토큰마다 태그를 붙이기 위해 사용\n",
        "* B(Beggining) : 개체명 __시작 단어__에 'B-개체명'으로 태그된다.\n",
        "* I(Inside) : B-개체명과 __연결되는 단어__일때 'I-개체명'으로 태그된다.\n",
        "* O(Outside) : __개체명 이외__의 모든 토큰에 태그된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELUlBibZPgcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b5eb78-48df-464d-e623-eb0fc1049960"
      },
      "source": [
        "# Bi-LSTM 모델 생성, 개체명 예측 예제\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# 학습 데이터 불러오는 함수\n",
        "def read_file(file_name):\n",
        "    # 라인별로 토큰 번호, 단어 토큰, 품사 태그, BIO 태그 정보를 불러온다.\n",
        "    sents = []\n",
        "    with open(file_name, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        for idx, I in enumerate(lines):\n",
        "            if I[0] == ';' and lines[idx + 1][0] == '$':\n",
        "                this_sent = []\n",
        "            elif I[0] == '$' and lines[idx - 1][0] == ';':\n",
        "                continue\n",
        "            elif I[0] == '\\n':\n",
        "                sents.append(this_sent)\n",
        "            else:\n",
        "                this_sent.append(tuple(I.split()))\n",
        "    return sents\n",
        "\n",
        "# 학습용 데이터 불러오기\n",
        "corpus = read_file('train.txt')\n",
        "\n",
        "# 말뭉치 데이터에서 단어와 BIO 태그만 불러와 학습용 데이터셋 생성\n",
        "sentences, tags = [], []\n",
        "for t in corpus:\n",
        "    tagged_sentence = []\n",
        "    sentence, bio_tag = [], []\n",
        "    for w in t:\n",
        "        tagged_sentence.append((w[1], w[3]))\n",
        "        sentence.append(w[1])\n",
        "        bio_tag.append(w[3])\n",
        "\n",
        "    sentences.append(sentence)   # 원본 문장의 분리된 단어 토큰 저장\n",
        "    tags.append(bio_tag)            # Bio 태그 정보들이 저장\n",
        "print('샘플 크기 : \\n', len(sentences))\n",
        "print('0번째 샘플 문장 시퀀스 : \\n', sentences[0])\n",
        "print('0번째 샘플 bio 태그 : \\n', tags[0])\n",
        "print('샘플 문장 시퀀스 최대 길이 : ', max(len(l) for l in sentences))\n",
        "print('샘플 문장 시퀀스 평균 길이 : ', (sum(map(len, sentences)) / len(sentences)))\n",
        "\n",
        "# 토크나이저 정의\n",
        "sent_tokenizer = preprocessing.text.Tokenizer(oov_token='OOV')  # 첫번째 인덱스에 OOV 사용\n",
        "sent_tokenizer.fit_on_texts(sentences)    # 앞에서 만들어진 단어 시퀀스와 태그 시퀀스를 사전으로 만들기 위해 토크나이저를 정의후 fit_on_texts 호출\n",
        "tag_tokenizer = preprocessing.text.Tokenizer(lower=False)  # 태그 정보는 소문자로 변환 X\n",
        "tag_tokenizer.fit_on_texts(tags)\n",
        "\n",
        "# 단어 사전 & 태그 사전 크기\n",
        "vocab_size = len(sent_tokenizer.word_index) + 1\n",
        "tag_size = len(tag_tokenizer.word_index) + 1\n",
        "print('BIO 태그 사전 크기 : ', tag_size)\n",
        "print('단어 사전 크기 : ', vocab_size)\n",
        "\n",
        "# 학습용 단어 시퀀스 생성\n",
        "x_train = sent_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
        "print(x_train[0])\n",
        "print(y_train[0])\n",
        "\n",
        "# index to word / NER 정의\n",
        "index_to_word = sent_tokenizer.index_word   # 시퀀스 인덱스를 단어로 변환하기 위해 사용\n",
        "index_to_ner = tag_tokenizer.index_word       # 시퀀스 인덱스를 NER로 변환하기 위해 사용\n",
        "index_to_ner[0] = 'PAD'\n",
        "\n",
        "# 시퀀스 패딩 처리\n",
        "max_len = 40\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, padding='post', maxlen=max_len)\n",
        "y_train = preprocessing.sequence.pad_sequences(y_train, padding='post', maxlen=max_len)\n",
        "\n",
        "# 학습 & 테스트 데이터 8:2로\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=.2, random_state=0)\n",
        "\n",
        "# 출력 데이터를 원-핫 인코딩\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=tag_size)\n",
        "print('학습 샘플 시퀀스 형상 : ', x_train.shape)\n",
        "print('학습 샘플 레이블 형상 : ', y_train.shape)\n",
        "print('테스트 샘플 시퀀스 형상 : ', x_test.shape)\n",
        "print('테스트 샘플 레이블 형상 : ', y_test.shape)\n",
        "\n",
        "# 모델 제작 : Bi-LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
        "print('모델 평가 : ', model.evaluate(x_test, y_test)[1])\n",
        "# 모델 평가시에 O 태그의 남용으로 성능과 무관하게 정확도가 높아지기에\n",
        "# 개체명 인식에 사용되는 성능평가인 F1 스코어를 사용해야한다.\n",
        "\n",
        "# 시퀀스를 NER 태그로 변환\n",
        "def sequences_to_tag(sequences):\n",
        "    result = []\n",
        "    for sequence in sequences:\n",
        "        temp = []\n",
        "        for pred in sequence:\n",
        "            pred_index = np.argmax(pred)\n",
        "            temp.append(index_to_ner[pred_index].replace('PAD', '0'))\n",
        "        result.append(temp)\n",
        "    return result\n",
        "\n",
        "# 테스트 데이터셋의 NER 예측\n",
        "y_predicted = model.predict(x_test)                # (711, 40) => model => (711, 40, 8)\n",
        "pred_tags = sequences_to_tag(y_predicted)      # 예측된 NER\n",
        "test_tags = sequences_to_tag(y_test)\n",
        "\n",
        "# F1 스코어 계산\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "# classification_report 함수로 NER 태그별 계산 정밀도 & 재현율 & F1 스코어 출력\n",
        "print(classification_report(test_tags, pred_tags))\n",
        "print('F1-score : {:.1%}'.format(f1_score(test_tags, pred_tags)))\n",
        "\n",
        "# 새로운 유형의 문장 NER 예측\n",
        "word_to_index = sent_tokenizer.word_index\n",
        "new_sentence = '삼성전자 출시 스마트폰 오늘 애플 도전장 내밀다.'.split()\n",
        "new_x = []\n",
        "for w in new_sentence:\n",
        "    try:\n",
        "        new_x.append(word_to_index.get(w, 1))\n",
        "    except KeyError:\n",
        "        # 모르는 단어 : OOV\n",
        "        new_x.append(word_to_index['OOV'])\n",
        "\n",
        "print('새로운 시퀀스 : ', new_x)\n",
        "new_padded_seqs = preprocessing.sequence.pad_sequences([new_x], padding='post', value=0, maxlen=max_len)\n",
        "\n",
        "# NER 예측\n",
        "p = model.predict(np.array([new_padded_seqs[0]]))\n",
        "p = np.argmax(p, axis=-1)  # 예측된 NER 인덱스값 추출\n",
        "\n",
        "print('{:10} {:5}'.format('단어', '예측된 NER'))\n",
        "print('-' * 50)\n",
        "for w, pred in zip(new_sentence, p[0]):\n",
        "    print('{:10} {:5}'.format(w, index_to_ner[pred]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플 크기 : \n",
            " 1995\n",
            "0번째 샘플 문장 시퀀스 : \n",
            " ['한편', ',', 'AFC', '챔피언스', '리그', 'E', '조', '에', '속하', 'ㄴ', '포항', '역시', '대회', '8강', '진출', '이', '불투명', '하', '다', '.']\n",
            "0번째 샘플 bio 태그 : \n",
            " ['O', 'O', 'O', 'O', 'O', 'B_OG', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "샘플 문장 시퀀스 최대 길이 :  143\n",
            "샘플 문장 시퀀스 평균 길이 :  30.727318295739348\n",
            "BIO 태그 사전 크기 :  8\n",
            "단어 사전 크기 :  9004\n",
            "[183, 12, 2552, 436, 100, 808, 348, 10, 1911, 7, 918, 551, 104, 719, 372, 4, 3948, 2, 8, 3]\n",
            "[1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "학습 샘플 시퀀스 형상 :  (1596, 40)\n",
            "학습 샘플 레이블 형상 :  (1596, 40, 8)\n",
            "테스트 샘플 시퀀스 형상 :  (399, 40)\n",
            "테스트 샘플 레이블 형상 :  (399, 40, 8)\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 17s 838ms/step - loss: 0.5358 - accuracy: 0.8149\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 11s 830ms/step - loss: 0.3072 - accuracy: 0.8753\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 11s 828ms/step - loss: 0.1939 - accuracy: 0.9041\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 11s 830ms/step - loss: 0.1490 - accuracy: 0.9228\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 11s 838ms/step - loss: 0.1150 - accuracy: 0.9370\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 11s 835ms/step - loss: 0.0909 - accuracy: 0.9508\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 11s 838ms/step - loss: 0.0706 - accuracy: 0.9633\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 11s 830ms/step - loss: 0.0535 - accuracy: 0.9736\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 11s 823ms/step - loss: 0.0387 - accuracy: 0.9809\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 11s 833ms/step - loss: 0.0291 - accuracy: 0.9864\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.2156 - accuracy: 0.9357\n",
            "모델 평가 :  0.9356999397277832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_OG seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_PS seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_DT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_LC seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_TI seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           _       0.52      0.46      0.49       259\n",
            "         _DT       0.77      0.87      0.81       144\n",
            "         _LC       0.74      0.42      0.54       170\n",
            "         _OG       0.76      0.56      0.65       252\n",
            "         _PS       0.78      0.42      0.54       209\n",
            "         _TI       0.73      0.70      0.72        27\n",
            "\n",
            "   micro avg       0.69      0.53      0.60      1061\n",
            "   macro avg       0.72      0.57      0.62      1061\n",
            "weighted avg       0.70      0.53      0.59      1061\n",
            "\n",
            "F1-score : 60.1%\n",
            "새로운 시퀀스 :  [2379, 1195, 3546, 239, 8211, 4453, 1]\n",
            "단어         예측된 NER\n",
            "--------------------------------------------------\n",
            "삼성전자       B_OG \n",
            "출시         O    \n",
            "스마트폰       O    \n",
            "오늘         B_DT \n",
            "애플         I    \n",
            "도전장        I    \n",
            "내밀다.       I    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM8uX4kchDRd"
      },
      "source": [
        "### F1 스코어 계산 요소\n",
        "* 정확도 : 실제 정답과의 유사도\n",
        "* 정밀도 : 결과값이 얼마나 일정하게 분포하는가\n",
        "* 재현율 : 정답인 것들중 모델이 정답이라 예측한 비율\n",
        "\n",
        ">F1 스코어는 정밀도와 재현율의 조화 평균이다\n",
        "\n",
        "__F1 score = 2 * ((정밀도 * 재현율) / (정밀도 + 재현율))__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODtnObiLhfHi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}